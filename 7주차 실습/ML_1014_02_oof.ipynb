{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N1SW6ecGN5h8"
   },
   "source": [
    "<font color=\"#CC3D3D\"><p>\n",
    "# OOF(Out-Of-Fold) Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Preparation ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "loan_data = pd.read_csv('loan_train.csv')\n",
    "y = loan_data['Personal Loan']\n",
    "X = loan_data.drop(['ID', 'ZIP Code', 'Personal Loan'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle에서 아래와 같이 학습데이터(X_train, y_train)와 평가데이터(X_test)를 나누어서 제공했다고 가정하자.\n",
    "# 즉, y_test는 제공하지 않기 때문에 우리는 X_test에 대한 정답을 모른다.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Engineering ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 예제에서는 생략되어 있지만 반드시 Feature Engineering이 요구된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Building #####\n",
    "*Hyperparameter Optimization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "#model = DecisionTreeClassifier()\n",
    "#model = LogisticRegression()\n",
    "#model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle Competition에서는 일반적으로 학습 데이터를 다시 나누지 않고 학습데이터 전체를 사용하여 model tuning을 한다.\n",
    "\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 조절할 하이퍼 파라미터와 그 범위를 지정하는 함수 정의\n",
    "def objective(trial): \n",
    "    knn_n_neighbors = trial.suggest_int('n_neighbors', 1, 10, step=1)\n",
    "    knn_weights = trial.suggest_categorical('weights', ['uniform','distance'])\n",
    "\n",
    "    classifier_obj = KNeighborsClassifier(\n",
    "        n_neighbors = knn_n_neighbors, \n",
    "        weights = knn_weights,    \n",
    "    )\n",
    "\n",
    "    score = cross_val_score(classifier_obj, X_train, y_train, scoring='roc_auc', cv=5)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# 최적화 실행\n",
    "study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=0), direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=18) \n",
    "\n",
    "#최적화 결과 보기\n",
    "print(\"Best score:\", study.best_value)\n",
    "print(\"Best parameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*OOF Prediction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle에서는 특정모형의 과대적합을 줄이기 위해 OOF(Out-Of-Fold) Prediction을 자주 사용한다. \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "models = cross_validate(KNeighborsClassifier(**study.best_params), # 최적화된 hyperparameter 사용\n",
    "                        X_train, y_train, cv=4, scoring='roc_auc', \n",
    "                        return_estimator=True)\n",
    "oof_pred = np.array([m.predict_proba(X_test)[:,1] for m in models['estimator']]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align='left' src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FpeM40%2FbtqS4NajVcL%2FwEkl1E6YsbdRMUs1yzVupK%2Fimg.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOF와 일반적인 방식(sklearn 권장 방식)의 성능 비교\n",
    "model = KNeighborsClassifier(**study.best_params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, oof_pred), roc_auc_score(y_test, model.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Ensemble ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 예제에서는 생략되어 있지만, 각 모델의 OOF prediction를 이용하여 앙상블하는 것이 일반적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xi-_0qA6N5hZ"
   },
   "source": [
    "<font color=\"#CC3D3D\"><p>\n",
    "# End"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "M3_code_02.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "TensorFlow 2.8 on Python 3.8 (CUDA 11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
